{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Pytorch Korea](https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html)\n",
        "\n",
        "코드는 파이토치 코리아를 참고하여 만들었습니다.\n",
        "\n",
        "더 알고 싶은 내용이 있다면 파이토치 코리아 링크를 따라가 보시기 바랍니다."
      ],
      "metadata": {
        "id": "FJobsuBhSeKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "aajTXEHeS2Lo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TORCH의 DATASET\n",
        "\n",
        "여기서는 토치 라이브러리에 저장된 데이터 셋(FashionMNIST)를 이용합니다.\n",
        "\n",
        "토치는 데이터 셋에 대한 전처리를 도와주는 라이브러리를 제공하고 있습니다.\n",
        "\n",
        "더 자세한 사항은 [DATASET](https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html)을 참고해 보시기 바랍니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "MW8iogT9THK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ToTensor\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16EL0AT_vlU5corNhN5HnPZ7lZuDCHLgw\" height=300, width = 500>\n",
        "\n",
        "이미지를 다루는 유명한 라이브러리들은 대부분 이미지 구조를 \"H x W x C\"로 이용합니다.\n",
        "하지만 Torch에서는 \"C x H x W\"의 배열 구조를 이용하기 때문에 이미지 배열을 바꿔줘야 합니다.\n",
        "\n",
        "\n",
        "\n",
        "1. 배열구조\n",
        "\"H x W x C\"  →  \"C x H x W\"\n",
        "\n",
        "\n",
        "\n",
        "2. 이미지 픽셀 밝기 정도(scale)\n",
        "\n",
        "  [0\\~255] >  [0~1]"
      ],
      "metadata": {
        "id": "oOHrDoXRZGPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #공개 데이터셋에서 학습 데이터를 내려받습니다.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2iIPJIoSyiD",
        "outputId": "c10e3c21-ef4e-4b0b-9493-7ccf69e1df93"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 14799103.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 272827.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5033397.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 20236435.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATALOADER\n",
        "\n",
        "우리는 대부분 SGD기반의 옵티마이저를 사용하기 때문에 data를 미니 배치로 나눠 줘야합니다.\n",
        "\n",
        "이 일을 DataLoader가 배치로 나눈 데이터를 준비해 줍니다.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1VmCLogiQ_iG5TBlHz4_rU9f3DNVniCuz\" height=300, width = 500>\n",
        "\n",
        "---\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1LfqmZTdGKFZuV9Sdy7osqYRCrk2mS7xZ\" height=300, width = 500>\n",
        "\n"
      ],
      "metadata": {
        "id": "7guOBxEwbgtB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "144MmftjSH3K",
        "outputId": "7074ecf3-db1c-4dc9-b077-b07ad8ca11cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# 데이터로더를 생성합니다.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 만들기\n",
        "\n",
        "이제 모델을 만들어 줄겁니다.\n",
        "\n",
        "우리가 늘 배우고 있는 아키텍쳐를 구현하여 만들 수 있습니다. class를 정의하여 만드는 것이 기본이고 모델 class는 반드시 nn.Module을 상속하고 forward함수를 가지고 있어야합니다.\n",
        "\n",
        "device라는 변수를 이용하여 gpu를 사용할지 cpu를 사용할지 결정해줍니다.\n",
        "\n",
        "이후  to(device)를 이용하여 모델과 데이터를 gpu로 보내는 과정이 gpu를 사용한다면 꼭 필요합니다.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1j8Q7Cvum5PLt8bpcpbO_O8FGuyAB-blb\" height=200, width = 200>\n"
      ],
      "metadata": {
        "id": "HrrGqj57dMUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습에 사용할 CPU나 GPU장치를 얻습니다.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# 모델을 정의합니다.\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILVA4wQqcqhB",
        "outputId": "4a3ec73f-9636-4059-8e59-c6246af86b51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 파라미터 최적화하기\n",
        "\n",
        "우리의 목적에 맞는 loss function과 optimizer를 결정해줍니다.\n",
        "\n",
        "우리는 현재 classification을 진행중이므로 cross entroopy를 이용해 보겠습니다.\n",
        "\n",
        "optimizer는 쉽게 SGD를 이용합니다."
      ],
      "metadata": {
        "id": "Qf7wMhGRevzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "K6qButmjehXV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAIN\n",
        "\n",
        "이제 Train함수를 만들어 보겠습니다.\n",
        "\n",
        "먼저  dataloader를 for문에 넣어서 미니 배치 하나를 받아옵니다.\n",
        "미니 배치는 to(device)를 이용해 gpu로 넣어줍니다.\n",
        "\n",
        "이제 모델을 이용해 입력 데이터의 prediction값을 얻고 loss function으로 실제 데이터와 prediction의 차이를 구합니다.\n",
        "\n",
        "이 차이를 이용하여 우리는 back propagation을 시작합니다. 역전파를 시작하기 전에 optimizer.zero_grad()를 이용하여 변수들을 초기화 합니다. 이렇게 하지 않으면 이전 iteration의 변수(gradient)가 누적되어 제대로된 결과를 가져오기 어렵습니다.\n",
        "\n",
        "loss.backward, optimizer.step은 이제 실제 역전파를 진행하는 함수라고 보면 될거 같네요."
      ],
      "metadata": {
        "id": "GZAt7zbBfObH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 예측 오류 계산\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "Xj_16Y4Tej0O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST\n",
        "\n",
        "이제 모델을 평가해봅시다.\n",
        "여기서는 model을 evaluation모드로 변경하고,\n",
        "평가는 gradient를 계산할 필요가 없으므로\n",
        "\n",
        " with torch.no_grad()를 이용해 gradient계산 과정을 없애줍니다.\n",
        "\n",
        " 다시 데이터를 gpu로 보내주고, 모델의 예측값을 꺼냅니다.\n",
        "\n",
        " 이후는 모델의 평균 로스 그리고 정확도를 구해주는 식입니다."
      ],
      "metadata": {
        "id": "SrL53ZgWglXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "VLS8Yhr5elz7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 에폭을 돌려볼까요!"
      ],
      "metadata": {
        "id": "XHtZ7cRKhX5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evz9s6rpem-N",
        "outputId": "ff7a9093-503a-4b85-add0-759ac6ce18c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.308099  [   64/60000]\n",
            "loss: 2.295934  [ 6464/60000]\n",
            "loss: 2.278307  [12864/60000]\n",
            "loss: 2.267631  [19264/60000]\n",
            "loss: 2.251933  [25664/60000]\n",
            "loss: 2.225580  [32064/60000]\n",
            "loss: 2.234968  [38464/60000]\n",
            "loss: 2.198143  [44864/60000]\n",
            "loss: 2.191296  [51264/60000]\n",
            "loss: 2.162457  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 45.1%, Avg loss: 2.158550 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.168748  [   64/60000]\n",
            "loss: 2.160011  [ 6464/60000]\n",
            "loss: 2.102834  [12864/60000]\n",
            "loss: 2.110499  [19264/60000]\n",
            "loss: 2.067503  [25664/60000]\n",
            "loss: 2.008153  [32064/60000]\n",
            "loss: 2.039857  [38464/60000]\n",
            "loss: 1.954283  [44864/60000]\n",
            "loss: 1.951712  [51264/60000]\n",
            "loss: 1.881391  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.0%, Avg loss: 1.880738 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.912465  [   64/60000]\n",
            "loss: 1.883477  [ 6464/60000]\n",
            "loss: 1.764920  [12864/60000]\n",
            "loss: 1.798863  [19264/60000]\n",
            "loss: 1.699602  [25664/60000]\n",
            "loss: 1.647169  [32064/60000]\n",
            "loss: 1.678764  [38464/60000]\n",
            "loss: 1.570791  [44864/60000]\n",
            "loss: 1.592939  [51264/60000]\n",
            "loss: 1.486860  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.6%, Avg loss: 1.507097 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.570642  [   64/60000]\n",
            "loss: 1.536752  [ 6464/60000]\n",
            "loss: 1.392642  [12864/60000]\n",
            "loss: 1.460199  [19264/60000]\n",
            "loss: 1.355077  [25664/60000]\n",
            "loss: 1.344660  [32064/60000]\n",
            "loss: 1.369158  [38464/60000]\n",
            "loss: 1.284537  [44864/60000]\n",
            "loss: 1.318584  [51264/60000]\n",
            "loss: 1.219908  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.1%, Avg loss: 1.246844 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.318155  [   64/60000]\n",
            "loss: 1.299638  [ 6464/60000]\n",
            "loss: 1.143758  [12864/60000]\n",
            "loss: 1.244557  [19264/60000]\n",
            "loss: 1.133887  [25664/60000]\n",
            "loss: 1.153523  [32064/60000]\n",
            "loss: 1.182186  [38464/60000]\n",
            "loss: 1.108421  [44864/60000]\n",
            "loss: 1.146384  [51264/60000]\n",
            "loss: 1.065716  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.4%, Avg loss: 1.086273 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 저장하기\n",
        "\n",
        "우리가 생성한 모델은 저장 할 수 있습니다.\n",
        "path를 정해주면 거기에 저장됩니다."
      ],
      "metadata": {
        "id": "rbCwu5qdhidl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7UCsNaAhlfI",
        "outputId": "a7d72230-1be1-4b26-86a3-625749a7490c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 불러오기\n",
        "\n",
        "저장된 모델을 다시 불러와 보죠!\n",
        "\n",
        "모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함됩니다."
      ],
      "metadata": {
        "id": "3j_cbR3Uhwow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svxgof1Ghx06",
        "outputId": "c3521955-a3f5-4e26-e70d-345464bcf1fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbBY3MTgiD-q",
        "outputId": "e794f40d-6e8a-4173-f2f1-2712cc0f20e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    }
  ]
}